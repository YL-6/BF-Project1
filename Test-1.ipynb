{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-16T10:06:16.196703Z",
     "start_time": "2025-06-16T10:06:08.207311Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_user_inputs():\n",
    "    # Get file name\n",
    "    file_name = input(\"Enter the file name (with extension, e.g., data.csv): \").strip()\n",
    "\n",
    "    # Get list of time series IDs to forecast\n",
    "    product_classes_input = input(\"Enter time series IDs to forecast, separated by commas: \").strip()\n",
    "    product_classes_to_forecast = [id_.strip() for id_ in product_classes_input.split(\",\") if id_.strip()]\n",
    "\n",
    "    # Get metric and validate\n",
    "    metric = input(\"Enter the metric ('mape' or 'mse'): \").strip().lower()\n",
    "    if metric not in ['mape', 'mse']:\n",
    "        raise ValueError(\"Invalid metric. Must be 'mape' or 'mse'.\")\n",
    "\n",
    "    return file_name, product_classes_to_forecast, metric\n",
    "\n",
    "\n",
    "def load_selected_timeseries(file_name: str, product_classes: list[str]) -> dict:\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    # Drop rows with missing essential values\n",
    "    df.dropna(subset=[\"product_class\", \"Month\", \"sales_volume\"], inplace=True)\n",
    "\n",
    "    # Convert Month to datetime\n",
    "    df[\"Month\"] = pd.to_datetime(df[\"Month\"], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"Month\"], inplace=True)\n",
    "\n",
    "    # Filter for selected product_classes\n",
    "    df = df[df[\"product_class\"].isin(product_classes)]\n",
    "\n",
    "    # Sort by date\n",
    "    df = df.sort_values(\"Month\")\n",
    "\n",
    "    # Group and extract time series with product class as name\n",
    "    time_series_dict = {\n",
    "        product_class: group.set_index(\"Month\")[\"sales_volume\"].sort_index().rename(product_class)\n",
    "        for product_class, group in df.groupby(\"product_class\")\n",
    "    }\n",
    "\n",
    "    return time_series_dict\n",
    "\n",
    "\n",
    "def check_seasonality_strength(ts: pd.Series, freq: int = 12, threshold: float = 0.5) -> str:\n",
    "    # Check for enough data\n",
    "    if len(ts) < 2 * freq:\n",
    "        return \"low\"  # Not enough data to assess seasonality\n",
    "\n",
    "    # Decompose the time series\n",
    "    decomposition = seasonal_decompose(ts, model='additive', period=freq, extrapolate_trend='freq')\n",
    "\n",
    "    # Compute strength of seasonality\n",
    "    resid = decomposition.resid.dropna()\n",
    "    seasonal = decomposition.seasonal.loc[resid.index]\n",
    "\n",
    "    var_resid = np.var(resid)\n",
    "    var_combined = np.var(resid + seasonal)\n",
    "\n",
    "    if var_combined == 0:\n",
    "        return \"low\"  # Avoid division by zero or flat series\n",
    "\n",
    "    strength = 1 - (var_resid / var_combined)\n",
    "\n",
    "    return \"high\" if strength >= threshold else \"low\"\n",
    "\n",
    "\n",
    "def select_category(ts: pd.Series):\n",
    "    \"\"\"Determines to which category a time series belongs.\"\"\"\n",
    "    if len(ts) < 48:\n",
    "        return \"Category 1\"\n",
    "    elif check_seasonality_strength(ts) == \"high\" and (ts == 0).any():\n",
    "        return \"Category 2\"\n",
    "    elif check_seasonality_strength(ts) == \"high\" and (ts > 0).all():\n",
    "        return \"Category 3\"\n",
    "    elif check_seasonality_strength(ts) == \"low\" and (ts == 0).any():\n",
    "        return \"Category 4\"\n",
    "    else:\n",
    "        return \"Category 5\"\n",
    "\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "categories = {\n",
    "    'Category 1': [\"naive\", \"drift\"],\n",
    "    'Category 2': [\"naive\", \"ETS\", \"seasonal naive\"],\n",
    "    'Category 3': [\"naive\", \"AutoARIMA\", \"ETS\", \"seasonal naive\"],\n",
    "    'Category 4': [\"naive\", \"AutoARIMA\", \"drift\", \"mean\"],\n",
    "    'Category 5': [\"naive\", \"AutoARIMA\", \"mean\"]\n",
    "}\n",
    "\n",
    "file_name, product_classes_to_forecast, metric = get_user_inputs()\n",
    "print(\n",
    "    f\"\\nInputs received:\\nFile: {file_name}\\nProduct Classes to Forecast: {product_classes_to_forecast}\\nMetric: {metric}\")\n",
    "\n",
    "ts_dict = load_selected_timeseries(file_name, product_classes_to_forecast)\n",
    "\n",
    "for p_class, series in ts_dict.items():\n",
    "    print(f\"\\nTime Series for {p_class}:\")\n",
    "    print(series)\n",
    "    print(select_category(series))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inputs received:\n",
      "File: proj1_exampleinput.csv\n",
      "Product Classes to Forecast: ['C1038', 'C2716', 'C6022']\n",
      "Metric: mape\n",
      "\n",
      "Time Series for C1038:\n",
      "Month\n",
      "2013-01-01    14212.0\n",
      "2013-02-01    11424.0\n",
      "2013-03-01    13432.0\n",
      "2013-04-01    13078.0\n",
      "2013-05-01    14356.0\n",
      "2013-06-01    17142.0\n",
      "2013-07-01    17377.0\n",
      "2013-08-01    13449.0\n",
      "2013-09-01    10185.0\n",
      "2013-10-01    10455.0\n",
      "2013-11-01    11432.0\n",
      "2013-12-01    31873.0\n",
      "2014-01-01    11997.0\n",
      "2014-02-01     9787.0\n",
      "2014-03-01     9037.0\n",
      "2014-04-01     7863.0\n",
      "2014-05-01     9472.0\n",
      "2014-06-01    14928.0\n",
      "2014-07-01    23856.0\n",
      "2014-08-01    26547.0\n",
      "2014-09-01    19960.0\n",
      "2014-10-01    18338.0\n",
      "2014-11-01    21364.0\n",
      "2014-12-01    45749.0\n",
      "2015-01-01    12426.0\n",
      "2015-02-01    12485.0\n",
      "2015-03-01    15622.0\n",
      "2015-04-01    15469.0\n",
      "2015-05-01    17695.0\n",
      "2015-06-01    14329.0\n",
      "2015-07-01    14573.0\n",
      "2015-08-01    17184.0\n",
      "2015-09-01    15990.0\n",
      "2015-10-01    17959.0\n",
      "2015-11-01    14598.0\n",
      "2015-12-01    32284.0\n",
      "2016-01-01    11957.0\n",
      "2016-02-01    12719.0\n",
      "2016-03-01    13801.0\n",
      "2016-04-01    15707.0\n",
      "2016-05-01    15949.0\n",
      "2016-06-01    13253.0\n",
      "2016-07-01    14066.0\n",
      "2016-08-01    13801.0\n",
      "2016-09-01    12980.0\n",
      "2016-10-01    13319.0\n",
      "2016-11-01    16821.0\n",
      "2016-12-01    42011.0\n",
      "2017-01-01    17092.0\n",
      "2017-02-01    11680.0\n",
      "2017-03-01    17091.0\n",
      "2017-04-01    19244.0\n",
      "2017-05-01    18969.0\n",
      "2017-06-01    18513.0\n",
      "2017-07-01    23531.0\n",
      "Name: C1038, dtype: float64\n",
      "Category 3\n",
      "\n",
      "Time Series for C2716:\n",
      "Month\n",
      "2013-01-01    16690.0\n",
      "2013-02-01    15426.0\n",
      "2013-03-01    17445.0\n",
      "2013-04-01    16493.0\n",
      "2013-05-01    16728.0\n",
      "2013-06-01    16195.0\n",
      "2013-07-01    16220.0\n",
      "2013-08-01    16998.0\n",
      "2013-09-01    18994.0\n",
      "2013-10-01    16204.0\n",
      "2013-11-01    14125.0\n",
      "2013-12-01    18779.0\n",
      "2014-01-01    24452.0\n",
      "2014-02-01    20696.0\n",
      "2014-03-01    23048.0\n",
      "2014-04-01    21467.0\n",
      "2014-05-01    23190.0\n",
      "2014-06-01    23209.0\n",
      "2014-07-01    23268.0\n",
      "2014-08-01    21549.0\n",
      "2014-09-01    21800.0\n",
      "2014-10-01    25668.0\n",
      "2014-11-01    24558.0\n",
      "2014-12-01    24795.0\n",
      "2015-01-01    29106.0\n",
      "2015-02-01    23992.0\n",
      "2015-03-01    29296.0\n",
      "2015-04-01    27262.0\n",
      "2015-05-01    27664.0\n",
      "2015-06-01    28941.0\n",
      "2015-07-01    29668.0\n",
      "2015-08-01    31284.0\n",
      "2015-09-01    30569.0\n",
      "2015-10-01    29416.0\n",
      "2015-11-01    28773.0\n",
      "2015-12-01    27447.0\n",
      "2016-01-01    31673.0\n",
      "2016-02-01    28153.0\n",
      "2016-03-01    31102.0\n",
      "2016-04-01    31240.0\n",
      "2016-05-01    32420.0\n",
      "2016-06-01    30907.0\n",
      "2016-07-01    31876.0\n",
      "2016-08-01    29627.0\n",
      "2016-09-01    31308.0\n",
      "2016-10-01    31204.0\n",
      "2016-11-01    29473.0\n",
      "2016-12-01    30079.0\n",
      "2017-01-01    34394.0\n",
      "2017-02-01    29085.0\n",
      "2017-03-01    32765.0\n",
      "2017-04-01    31353.0\n",
      "2017-05-01    34470.0\n",
      "2017-06-01    34994.0\n",
      "2017-07-01    34691.0\n",
      "Name: C2716, dtype: float64\n",
      "Category 3\n",
      "\n",
      "Time Series for C6022:\n",
      "Month\n",
      "2014-03-01     72.0\n",
      "2014-07-01    163.0\n",
      "2014-09-01    160.0\n",
      "2014-10-01     50.0\n",
      "2014-11-01      5.0\n",
      "2014-12-01    169.0\n",
      "2015-06-01    207.0\n",
      "2015-07-01    301.0\n",
      "2015-08-01    417.0\n",
      "2015-09-01    359.0\n",
      "2015-10-01     62.0\n",
      "2015-11-01      4.0\n",
      "2015-12-01    179.0\n",
      "2016-01-01    311.0\n",
      "2016-02-01    418.0\n",
      "2016-03-01    442.0\n",
      "2016-04-01    365.0\n",
      "2016-05-01    455.0\n",
      "2016-06-01    436.0\n",
      "2016-07-01    381.0\n",
      "2016-08-01    457.0\n",
      "2016-09-01    488.0\n",
      "2016-10-01    476.0\n",
      "2016-11-01    452.0\n",
      "2016-12-01    485.0\n",
      "2017-01-01    488.0\n",
      "2017-02-01    441.0\n",
      "2017-03-01    442.0\n",
      "2017-04-01    298.0\n",
      "2017-05-01    279.0\n",
      "2017-06-01    295.0\n",
      "2017-07-01    351.0\n",
      "Name: C6022, dtype: float64\n",
      "Category 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:17:32.101624Z",
     "start_time": "2025-06-16T10:17:32.095602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast import StatsForecast\n",
    "\n",
    "\n",
    "def naive_forecast(series: pd.Series, horizon: int) -> np.ndarray:\n",
    "    last_value = series.iloc[-1]\n",
    "    return np.repeat(last_value, horizon)\n",
    "\n",
    "\n",
    "def drift_forecast(series: pd.Series, horizon: int) -> np.ndarray:\n",
    "    n = len(series)\n",
    "    if n < 2:\n",
    "        return np.repeat(series.iloc[-1], horizon)\n",
    "    drift = (series.iloc[-1] - series.iloc[0]) / (n - 1)\n",
    "    return series.iloc[-1] + drift * np.arange(1, horizon + 1)\n",
    "\n",
    "\n",
    "def seasonal_naive_forecast(series: pd.Series, horizon: int, season_length: int = 12) -> np.ndarray:\n",
    "    if len(series) < season_length:\n",
    "        raise ValueError(\"Not enough data for seasonal naive forecast\")\n",
    "    last_season = series.iloc[-season_length:]\n",
    "    reps = int(np.ceil(horizon / season_length))\n",
    "    return np.tile(last_season.values, reps)[:horizon]\n",
    "\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "\n",
    "def ets_forecast(series: pd.Series, horizon: int) -> np.ndarray:\n",
    "    try:\n",
    "        # try multiplicative\n",
    "        model = ExponentialSmoothing(series, trend=\"add\", seasonal=\"mul\", seasonal_periods=12)\n",
    "        fitted_model = model.fit()\n",
    "    except Exception:\n",
    "        # additive\n",
    "        model = ExponentialSmoothing(series, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "        fitted_model = model.fit()\n",
    "    return fitted_model.forecast(horizon)\n",
    "\n",
    "\n",
    "def autoarima_forecast(series: pd.Series, horizon: int) -> np.ndarray:\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'unique_id': ['ts1'] * len(series),\n",
    "        'ds': series.index,\n",
    "        'y': series.values\n",
    "    })\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        sf = StatsForecast(\n",
    "            models=[AutoARIMA(season_length=12)],\n",
    "            freq='MS',\n",
    "            n_jobs=1\n",
    "        )\n",
    "        forecasts_df = sf.forecast(df=df, h=horizon)\n",
    "        return forecasts_df['AutoARIMA'].values\n",
    "\n",
    "\n",
    "class HistoricAverageModel:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, series: pd.Series):\n",
    "        self.mean = series.mean()\n",
    "\n",
    "    def forecast(self, horizon: int) -> np.ndarray:\n",
    "        return np.repeat(self.mean, horizon)\n"
   ],
   "id": "7aa37a881212e479",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:23:39.335477Z",
     "start_time": "2025-06-16T10:23:39.330751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def simulate_forecasting(ts_dict, categories, metric, forecast_horizon=12, retrain_every=6, eval_periods=24):\n",
    "    all_results = []\n",
    "\n",
    "    for ts_id, series in tqdm(ts_dict.items(), desc=\"Processing Time Series\"):\n",
    "        series = series.dropna()\n",
    "        category = select_category(series)\n",
    "        models = categories[category]\n",
    "\n",
    "        if len(series) < 32:\n",
    "            print(f\"\\nSkipping {ts_id} - only {len(series)} observations.\")\n",
    "            continue\n",
    "\n",
    "        max_date = series.index.max()\n",
    "\n",
    "        for i in range(0, eval_periods, retrain_every):\n",
    "            train_end = max_date - relativedelta(months=(forecast_horizon + i))\n",
    "            test_start = train_end + relativedelta(months=1)\n",
    "            test_end = test_start + relativedelta(months=forecast_horizon - 1)\n",
    "\n",
    "            train = series[:train_end]\n",
    "            test = series[test_start:test_end]\n",
    "\n",
    "            if len(test) < forecast_horizon or len(train) < 12:\n",
    "                continue\n",
    "\n",
    "            for model_name in models:\n",
    "                try:\n",
    "                    # Select prediction method\n",
    "                    if model_name == \"naive\":\n",
    "                        pred = naive_forecast(train, forecast_horizon)\n",
    "                    elif model_name == \"drift\":\n",
    "                        pred = drift_forecast(train, forecast_horizon)\n",
    "                    elif model_name == \"seasonal naive\":\n",
    "                        pred = seasonal_naive_forecast(train, forecast_horizon)\n",
    "                    elif model_name == \"ETS\":\n",
    "                        pred = ets_forecast(train, forecast_horizon)\n",
    "                    elif model_name == \"AutoARIMA\":\n",
    "                        pred = autoarima_forecast(train, forecast_horizon)\n",
    "                    elif model_name == \"mean\":\n",
    "                        model = HistoricAverageModel()\n",
    "                        model.fit(train)\n",
    "                        pred = model.forecast(forecast_horizon)\n",
    "                    else:\n",
    "                        continue  # Skip unknown model\n",
    "                except Exception as e:\n",
    "                    print(f\"Model {model_name} failed for {ts_id}: {e}\")\n",
    "                    pred = np.full(forecast_horizon, np.nan)\n",
    "\n",
    "                # Evaluate\n",
    "                pred = pd.Series(pred, index=test.index)\n",
    "                if metric == \"mape\":\n",
    "                    if (test == 0).any():\n",
    "                        warnings.warn(f\"MAPE warning for {ts_id} – true values contain zeros.\")\n",
    "                    error = np.mean(np.abs((test - pred) / np.maximum(test, 1e-8)))\n",
    "                else:\n",
    "                    error = np.mean((test - pred) ** 2)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"ts_id\": ts_id,\n",
    "                    \"category\": category,\n",
    "                    \"model\": model_name,\n",
    "                    \"train_end\": train_end.date(),\n",
    "                    \"test_start\": test_start.date(),\n",
    "                    \"test_end\": test_end.date(),\n",
    "                    metric: error\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ],
   "id": "40324eea2a00e65b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:23:44.579600Z",
     "start_time": "2025-06-16T10:23:43.478021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = simulate_forecasting(\n",
    "    ts_dict=ts_dict,\n",
    "    categories=categories,\n",
    "    metric=metric,\n",
    "    forecast_horizon=12,\n",
    "    retrain_every=6,\n",
    "    eval_periods=24\n",
    ")\n",
    "\n",
    "results_df"
   ],
   "id": "8f98d3f343541671",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Time Series:   0%|          | 0/3 [00:00<?, ?it/s]/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "Processing Time Series:  33%|███▎      | 1/3 [00:00<00:01,  1.44it/s]/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "Processing Time Series: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    ts_id    category           model   train_end  test_start    test_end  \\\n",
       "0   C1038  Category 3           naive  2016-07-01  2016-08-01  2017-07-01   \n",
       "1   C1038  Category 3           ARIMA  2016-07-01  2016-08-01  2017-07-01   \n",
       "2   C1038  Category 3             ETS  2016-07-01  2016-08-01  2017-07-01   \n",
       "3   C1038  Category 3  seasonal naive  2016-07-01  2016-08-01  2017-07-01   \n",
       "4   C1038  Category 3           naive  2016-01-01  2016-02-01  2017-01-01   \n",
       "5   C1038  Category 3           ARIMA  2016-01-01  2016-02-01  2017-01-01   \n",
       "6   C1038  Category 3             ETS  2016-01-01  2016-02-01  2017-01-01   \n",
       "7   C1038  Category 3  seasonal naive  2016-01-01  2016-02-01  2017-01-01   \n",
       "8   C1038  Category 3           naive  2015-07-01  2015-08-01  2016-07-01   \n",
       "9   C1038  Category 3           ARIMA  2015-07-01  2015-08-01  2016-07-01   \n",
       "10  C1038  Category 3             ETS  2015-07-01  2015-08-01  2016-07-01   \n",
       "11  C1038  Category 3  seasonal naive  2015-07-01  2015-08-01  2016-07-01   \n",
       "12  C1038  Category 3           naive  2015-01-01  2015-02-01  2016-01-01   \n",
       "13  C1038  Category 3           ARIMA  2015-01-01  2015-02-01  2016-01-01   \n",
       "14  C1038  Category 3             ETS  2015-01-01  2015-02-01  2016-01-01   \n",
       "15  C1038  Category 3  seasonal naive  2015-01-01  2015-02-01  2016-01-01   \n",
       "16  C2716  Category 3           naive  2016-07-01  2016-08-01  2017-07-01   \n",
       "17  C2716  Category 3           ARIMA  2016-07-01  2016-08-01  2017-07-01   \n",
       "18  C2716  Category 3             ETS  2016-07-01  2016-08-01  2017-07-01   \n",
       "19  C2716  Category 3  seasonal naive  2016-07-01  2016-08-01  2017-07-01   \n",
       "20  C2716  Category 3           naive  2016-01-01  2016-02-01  2017-01-01   \n",
       "21  C2716  Category 3           ARIMA  2016-01-01  2016-02-01  2017-01-01   \n",
       "22  C2716  Category 3             ETS  2016-01-01  2016-02-01  2017-01-01   \n",
       "23  C2716  Category 3  seasonal naive  2016-01-01  2016-02-01  2017-01-01   \n",
       "24  C2716  Category 3           naive  2015-07-01  2015-08-01  2016-07-01   \n",
       "25  C2716  Category 3           ARIMA  2015-07-01  2015-08-01  2016-07-01   \n",
       "26  C2716  Category 3             ETS  2015-07-01  2015-08-01  2016-07-01   \n",
       "27  C2716  Category 3  seasonal naive  2015-07-01  2015-08-01  2016-07-01   \n",
       "28  C2716  Category 3           naive  2015-01-01  2015-02-01  2016-01-01   \n",
       "29  C2716  Category 3           ARIMA  2015-01-01  2015-02-01  2016-01-01   \n",
       "30  C2716  Category 3             ETS  2015-01-01  2015-02-01  2016-01-01   \n",
       "31  C2716  Category 3  seasonal naive  2015-01-01  2015-02-01  2016-01-01   \n",
       "32  C6022  Category 1           naive  2016-07-01  2016-08-01  2017-07-01   \n",
       "33  C6022  Category 1           drift  2016-07-01  2016-08-01  2017-07-01   \n",
       "34  C6022  Category 1           naive  2016-01-01  2016-02-01  2017-01-01   \n",
       "35  C6022  Category 1           drift  2016-01-01  2016-02-01  2017-01-01   \n",
       "\n",
       "        mape  \n",
       "0   0.226352  \n",
       "1   0.228920  \n",
       "2   0.363437  \n",
       "3   0.233362  \n",
       "4   0.212497  \n",
       "5   0.296125  \n",
       "6   0.191240  \n",
       "7   0.156810  \n",
       "8   0.141168  \n",
       "9   0.125909  \n",
       "10  3.398030  \n",
       "11  0.177187  \n",
       "12  0.216242  \n",
       "13  0.342223  \n",
       "14  1.770790  \n",
       "15  0.333906  \n",
       "16  0.059612  \n",
       "17  0.088235  \n",
       "18  0.104073  \n",
       "19  0.055918  \n",
       "20  0.042829  \n",
       "21  0.082039  \n",
       "22  0.057467  \n",
       "23  0.078332  \n",
       "24  0.050792  \n",
       "25  0.097037  \n",
       "26  0.086259  \n",
       "27  0.138533  \n",
       "28  0.053761  \n",
       "29  0.069812  \n",
       "30  0.074175  \n",
       "31  0.182362  \n",
       "32  0.205924  \n",
       "33  0.332975  \n",
       "34  0.295787  \n",
       "35  0.092284  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_id</th>\n",
       "      <th>category</th>\n",
       "      <th>model</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.226352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.228920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.363437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.233362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.212497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.296125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.191240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.156810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.141168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.125909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>3.398030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.177187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.216242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.342223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.770790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C1038</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.333906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.059612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.104073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.055918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.042829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.082039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.057467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.078332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.050792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.097037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.086259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.138533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>naive</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.053761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.069812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>ETS</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.074175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>C2716</td>\n",
       "      <td>Category 3</td>\n",
       "      <td>seasonal naive</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.182362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>C6022</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.205924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>C6022</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>drift</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.332975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>C6022</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>naive</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.295787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>C6022</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>drift</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.092284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T10:43:40.462255Z",
     "start_time": "2025-06-16T10:43:40.446244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_models(\n",
    "    results_df: pd.DataFrame,\n",
    "    ts_dict: dict,\n",
    "    metric: str,\n",
    "    naive_model_name: str = 'naive',\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate model performance and select the best model per time series.\n",
    "    Warn if MAPE is used on series with zero values.\n",
    "\n",
    "    Returns a DataFrame with columns: 'ts_id', 'best_model', 'metric', 'naive_metric'\n",
    "    \"\"\"\n",
    "    if results_df.empty:\n",
    "        print(\"No results to evaluate.\")\n",
    "        return pd.DataFrame(columns=['ts_id', 'best_model', metric, 'naive_metric'])\n",
    "\n",
    "    if metric not in results_df.columns:\n",
    "        raise ValueError(f\"Metric '{metric}' not found in results_df columns: {results_df.columns.tolist()}\")\n",
    "\n",
    "    # Warn about MAPE on zero values\n",
    "    if metric.lower() == 'mape':\n",
    "        zero_series = [ts_id for ts_id, ts in ts_dict.items() if (ts == 0).any()]\n",
    "        if zero_series:\n",
    "            print(\"WARNING: MAPE is being used on series with zero values:\")\n",
    "            print(\"Affected time series IDs:\", zero_series)\n",
    "\n",
    "    # Compute mean error per model per series\n",
    "    avg_perf = (\n",
    "        results_df\n",
    "        .groupby(['ts_id', 'model'])[metric]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f'avg_{metric}'})\n",
    "    )\n",
    "\n",
    "    # Find best model per time series (lowest error)\n",
    "    best_model_df = (\n",
    "        avg_perf.loc[\n",
    "            avg_perf.groupby('ts_id')[f'avg_{metric}'].idxmin()\n",
    "        ]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    best_model_df.rename(columns={\n",
    "        'model': 'best_model',\n",
    "        f'avg_{metric}': metric\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add baseline (naive) model's performance\n",
    "    naive_perf = avg_perf[avg_perf['model'] == naive_model_name][['ts_id', f'avg_{metric}']]\n",
    "    naive_perf.rename(columns={f'avg_{metric}': 'naive_metric'}, inplace=True)\n",
    "\n",
    "    result_df = pd.merge(best_model_df, naive_perf, on='ts_id', how='left')\n",
    "\n",
    "    # Ensure desired column order\n",
    "    result_df = result_df[['ts_id', 'best_model', metric, 'naive_metric']]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Best model per time series based on lowest average error:\")\n",
    "        print(result_df)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "best_models_df = evaluate_models(results_df, ts_dict, metric)"
   ],
   "id": "7c176d355dba2ca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model per time series based on lowest average error:\n",
      "   ts_id best_model      mape  naive_metric\n",
      "0  C1038      naive  0.199065      0.199065\n",
      "1  C2716      naive  0.051749      0.051749\n",
      "2  C6022      drift  0.212629      0.250856\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
