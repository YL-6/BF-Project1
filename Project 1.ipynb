{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 1",
   "id": "cd09c6ee40904d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:30:39.029998Z",
     "start_time": "2025-06-11T08:30:34.022827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from coreforecast.scalers import boxcox, boxcox_lambda\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.arima import arima_string\n",
    "from statsforecast.models import AutoARIMA, SeasonalNaive\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "# Read data\n"
   ],
   "id": "30e21e231fac9642",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'ds'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtsa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstattools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m kpss\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Read data\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproj1_exampleinput.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, parse_dates\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1895\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m   1897\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1898\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mapping[engine](f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions)\n\u001B[1;32m   1899\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1900\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m    155\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_usecols_names(\n\u001B[1;32m    156\u001B[0m             usecols,\n\u001B[1;32m    157\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames,  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m    158\u001B[0m         )\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_parse_dates_presence(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames)  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_noconvert_columns()\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/mysampleProject/lib/python3.12/site-packages/pandas/io/parsers/base_parser.py:243\u001B[0m, in \u001B[0;36mParserBase._validate_parse_dates_presence\u001B[0;34m(self, columns)\u001B[0m\n\u001B[1;32m    233\u001B[0m missing_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28msorted\u001B[39m(\n\u001B[1;32m    235\u001B[0m         {\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    240\u001B[0m     )\n\u001B[1;32m    241\u001B[0m )\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing_cols:\n\u001B[0;32m--> 243\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing column provided to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparse_dates\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_cols\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    245\u001B[0m     )\n\u001B[1;32m    246\u001B[0m \u001B[38;5;66;03m# Convert positions to actual column names\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m    248\u001B[0m     col \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(col, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns) \u001B[38;5;28;01melse\u001B[39;00m columns[col]\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m cols_needed\n\u001B[1;32m    250\u001B[0m ]\n",
      "\u001B[0;31mValueError\u001B[0m: Missing column provided to 'parse_dates': 'ds'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question C\n",
    "\n",
    "Category 1: shorter than 2 seasonality periods\n",
    "#### Models: Drift\n",
    "Applicable situations: short series with linear trend.\n",
    "Working principle: use the slope of the line connecting the first and last points to linearly extrapolate future values.\n",
    "Advantages: can capture simple trend components.\n",
    "Conclusion: if the data is short but has a trend, drift is better than naive.\n",
    "\n",
    "Category 2: contains zeroes and has high seasonality\n",
    "Model 1: Seasonal Naive\n",
    "In a series with strong seasonality, simply repeat the value of the previous season, which is suitable for time series containing zero values.\n",
    "Model 2: ETS (Exponential Smoothing)\n",
    "If you choose models such as ETS(M,A,N) or ETS(A,A,N), you can handle series with seasonality and non-negative numbers.\n",
    "But note: some ETS combinations are sensitive to zero values (such as multiplicative models) and need to use additive forms.\n",
    "Model 3: TSLM\n",
    "Seasonal dummy variables can be introduced to model strong seasonality, which is also more robust to zero values.\n",
    "\n",
    "Category 3:\n",
    "\n",
    "\n",
    "Category 4:\n",
    "\n",
    "\n",
    "Category 5:\n",
    "\n",
    "\n"
   ],
   "id": "83aed0a42c2eaebe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
